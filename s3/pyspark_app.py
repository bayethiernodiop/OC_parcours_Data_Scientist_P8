# -*- coding: utf-8 -*-

# LOCAL RUN: 
# spark-submit --driver-memory 10g --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 pyspark_app.py .

# CLUSTER RUN:
# spark-submit --deploy-mode client --master yarn --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 --deploy-mode client --executor-memory 18g --num-executors 8 --executor-cores 5 s3://p8-fruits/pyspark_app.py s3://p8-fruits/


##################################
# Import libraries
##################################

import sys, os
from pyspark.sql import SparkSession
from pyspark.sql.functions import split, element_at
from sparkdl import DeepImageFeaturizer
from datetime import datetime


# Main function
if __name__ == "__main__":

    ##################################
    # Creating SparkSession
    ##################################

    spark = (
        SparkSession
        .builder
        .appName("p8_featurizer")
        .getOrCreate()
    )

    ##################################
    # Loading images
    ##################################

    ROOT_PATH = sys.argv[1]

    # Parsing the "train" dataset. Use data/*/** for training + testing sets
    DATA_PATH = os.path.join(ROOT_PATH, "data/Training/**")

    print("Loading images...")
    image_df = (
        spark
        .read
        .format("image")
        .load(DATA_PATH)
    )

    print("Images loaded.")

    # Sampling for test mode
    image_df = image_df.limit(300) # REMOVE FOR PROD
    print("Images count:", image_df.count())
        
    image_df.repartition(30)
    
    
    ##################################
    # Getting the labels (targets)
    ##################################

    

    # Getting the label by splitting the path of the image and getting its last directory
    print("Generating labels...")
    image_df = (image_df
                .withColumn(
                    'label',
                    element_at(
                        split(
                            image_df['image.origin'],
                            "/"),
                        -2)))

    image_df.show(2)
    print("Labels generated.")
    

    ##################################
    # DEBUG
    ##################################
    
    image_df.repartition(30)
    print("Number of partitions:", image_df.rdd.getNumPartitions())
    

    ##################################
    # Dimensional reduction
    ##################################

    from sparkdl import DeepImageFeaturizer
    
    # Instanciate featurizer generated by ResNet50
    featurizer = DeepImageFeaturizer(
        inputCol="image",
        outputCol="features",
        modelName="ResNet50"
    )

    # Apply the featurizer to our image_df DataFrame
    features_df = featurizer\
        .transform(image_df)\
        .select("features", "label", "image.origin")



    #######################################
    # Log results locally, as Parquet file
    #######################################

    # datetime object containing current date and time
    now = datetime.now()
     
    # Converting to string in the format dd-mm-YY H:M:S
    t_string = now.strftime("%b-%d-%Y %H:%M:%S")

    # Creating the path for storing the results
    RESULTS_PATH = os.path.join(ROOT_PATH, "results", t_string)

    print("Saving results...")
    features_df.write.format("parquet").mode("overwrite").save(RESULTS_PATH)
    print("Results saved.")


    ####################################
    # Closing the sparkSession
    ####################################

    spark.stop()
    print("SparkSession stopped.")