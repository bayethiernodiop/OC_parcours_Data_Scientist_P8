# -*- coding: utf-8 -*-

# LOCAL RUN: 
# spark-submit --driver-memory 10g --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 pyspark_app.py .

# CLUSTER RUN:
# spark-submit --deploy-mode client --master yarn --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 --deploy-mode client --executor-memory 7g --num-executors 5 --executor-cores 4 s3://p8-fruits/pyspark_app.py s3://p8-fruits/


##################################
# Import libraries
##################################

import sys, os
from pyspark.sql import SparkSession
from pyspark.sql.functions import split, element_at
from sparkdl import DeepImageFeaturizer
from datetime import datetime


##################################
# Creating SparkSession
##################################

spark = (
    SparkSession
    .builder
    .appName("p8_featurizer")
    .getOrCreate()
)


##################################
# Loading images
##################################

ROOT_PATH = sys.argv[1]

# Parsing the "train" dataset. Use data/*/** for training + testing sets
DATA_PATH = os.path.join(ROOT_PATH, "data/Training/**")

print("Loading images...")
image_df = (
    spark
    .read
    .format("image")
    .load(DATA_PATH)
)

# Sampling for test mode (df.limit collect to the driver)
image_df = image_df.limit(300) # REMOVE FOR PROD
image_df = image_df.repartition(30)

print("Number of partitions:", image_df.rdd.getNumPartitions())


##################################
# Getting the labels (targets)
##################################

# Getting the label by splitting the path of the image and getting its last directory
image_df = (image_df
            .withColumn(
                'label',
                element_at(
                    split(
                        image_df['image.origin'],
                        "/"),
                    -2)))


##################################
# Dimensional reduction
##################################

from sparkdl import DeepImageFeaturizer

# Instanciate featurizer generated by ResNet50
featurizer = DeepImageFeaturizer(
    inputCol="image",
    outputCol="features",
    modelName="ResNet50"
)

# Apply the featurizer to our image_df DataFrame
print("Generating features...")
image_df = featurizer\
    .transform(image_df)\
    .select("features", "label", "image.origin")

#######################################
# Log results locally, as Parquet file
#######################################

# datetime object containing current date and time
now = datetime.now()
    
# Converting to string in the format dd-mm-YY H:M:S
t_string = now.strftime("%b-%d-%Y %H:%M:%S")

# Creating the path for storing the results
RESULTS_PATH = os.path.join(ROOT_PATH, "results", t_string)

image_df.write.format("parquet").mode("overwrite").save(RESULTS_PATH)


####################################
# Closing the sparkSession
####################################

spark.stop()
print("Spark application successfully finished.")