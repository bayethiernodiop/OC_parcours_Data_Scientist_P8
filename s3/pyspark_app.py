# -*- coding: utf-8 -*-

# LOCAL RUN: 
# spark-submit --executor-memory 10g --driver-memory 10g --num-executors 2 --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 pyspark_app.py .
# spark-submit --driver-memory 10g --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 pyspark_app.py .

# CLUSTER RUN:
# spark-submit --master yarn --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11 --deploy-mode cluster pyspark_app.py s3://p8-fruits/

##################################
# Import libraries
##################################

import sys, os
from pyspark.sql import SparkSession
from sparkdl import DeepImageFeaturizer


# Main function
if __name__ == "__main__":


    ##################################
    # Creating SparkSession
    ##################################

    spark = (SparkSession
                .builder
                .appName("p8_featurizer")
                .getOrCreate()
    )

    ##################################
    # Loading images
    ##################################

    ROOT_PATH = sys.argv[1]

    # RUN MODE
    DATA_PATH = os.path.join(ROOT_PATH, "data/")

    # TEST MODE
    DATA_PATH = os.path.join(ROOT_PATH, "data/Test/Apricot/") # REMOVE for production

    image_df = spark.read.format("image").load(DATA_PATH)
    image_df.repartition(180)
    
    print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$")
    print(image_df.rdd.getNumPartitions())
    print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$")

    ##################################
    # Pre-processing
    ##################################

    # img_count = image_df.count()



    ##################################
    # Dimensional reduction
    ##################################

    # Instanciate featurizer generated by ResNet50
    featurizer = DeepImageFeaturizer(inputCol="image", outputCol="features", modelName="ResNet50")

    # TEST MODE
    # image_df = image_df.limit(10) # REMOVE for production

    # Apply the featurizer to our image_df DataFrame
    features_df = featurizer.transform(image_df)


    #######################################
    # Log results locally, as Parquet file
    #######################################

    RESULTS_PATH = os.path.join(ROOT_PATH, "results")
    features_df.write.format("parquet").mode("overwrite").save(RESULTS_PATH)


    ####################################
    # Closing the sparkSession
    ####################################

    spark.stop()